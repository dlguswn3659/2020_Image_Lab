{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "mnist-svhn-example.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyNUnwT5Bz8Bcl+5a36uOI39",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/dlguswn3659/2020_Image_Lab/blob/master/mnist_svhn_example.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1Q7wE-0-uKDM",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "aa235e20-748c-4fa6-f64b-a3c04d44301b"
      },
      "source": [
        "!git clone https://github.com/yunjey/mnist-svhn-transfer.git\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "fatal: destination path 'mnist-svhn-transfer' already exists and is not an empty directory.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "06OKcRM8vkY2",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "44e1db30-2846-4dd2-9074-49b4665dd4c0"
      },
      "source": [
        "cd /content/mnist-svhn-transfer/"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/mnist-svhn-transfer\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bsqltIzrvnIf",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "outputId": "069784c2-5442-4720-c851-07071ad77648"
      },
      "source": [
        "!ls"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "data_loader.py\tgif\t main.py   README.md\n",
            "download.sh\tLICENSE  model.py  solver.py\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Gh3hPtwQuUEJ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 611
        },
        "outputId": "5a7c73be-507b-4d71-b239-df1298c277cf"
      },
      "source": [
        "! chmod +x download.sh\n",
        "! ./download.sh"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2020-07-19 06:24:42--  http://ufldl.stanford.edu/housenumbers/train_32x32.mat\n",
            "Resolving ufldl.stanford.edu (ufldl.stanford.edu)... 171.64.68.10\n",
            "Connecting to ufldl.stanford.edu (ufldl.stanford.edu)|171.64.68.10|:80... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 182040794 (174M) [text/plain]\n",
            "Saving to: ‘svhn/train_32x32.mat’\n",
            "\n",
            "svhn/train_32x32.ma 100%[===================>] 173.61M  19.0MB/s    in 14s     \n",
            "\n",
            "2020-07-19 06:24:56 (12.7 MB/s) - ‘svhn/train_32x32.mat’ saved [182040794/182040794]\n",
            "\n",
            "--2020-07-19 06:24:56--  http://ufldl.stanford.edu/housenumbers/test_32x32.mat\n",
            "Resolving ufldl.stanford.edu (ufldl.stanford.edu)... 171.64.68.10\n",
            "Connecting to ufldl.stanford.edu (ufldl.stanford.edu)|171.64.68.10|:80... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 64275384 (61M) [text/plain]\n",
            "Saving to: ‘svhn/test_32x32.mat’\n",
            "\n",
            "svhn/test_32x32.mat 100%[===================>]  61.30M  13.2MB/s    in 8.7s    \n",
            "\n",
            "2020-07-19 06:25:05 (7.01 MB/s) - ‘svhn/test_32x32.mat’ saved [64275384/64275384]\n",
            "\n",
            "--2020-07-19 06:25:05--  http://ufldl.stanford.edu/housenumbers/extra_32x32.mat\n",
            "Resolving ufldl.stanford.edu (ufldl.stanford.edu)... 171.64.68.10\n",
            "Connecting to ufldl.stanford.edu (ufldl.stanford.edu)|171.64.68.10|:80... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 1329278602 (1.2G) [text/plain]\n",
            "Saving to: ‘svhn/extra_32x32.mat’\n",
            "\n",
            "svhn/extra_32x32.ma 100%[===================>]   1.24G  19.3MB/s    in 70s     \n",
            "\n",
            "2020-07-19 06:26:15 (18.1 MB/s) - ‘svhn/extra_32x32.mat’ saved [1329278602/1329278602]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "20cYFFbKuV6C",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 973
        },
        "outputId": "979226f0-425e-48df-f65e-41f69e155201"
      },
      "source": [
        "! python main.py --use_labels=False --use_reconst_loss=True"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Namespace(batch_size=64, beta1=0.5, beta2=0.999, d_conv_dim=64, g_conv_dim=64, image_size=32, log_step=10, lr=0.0002, mnist_path='./mnist', mode='train', model_path='./models', num_classes=10, num_workers=2, sample_path='./samples', sample_step=500, svhn_path='./svhn', train_iters=40000, use_labels=False, use_reconst_loss=True)\n",
            "/usr/local/lib/python3.6/dist-packages/torchvision/transforms/transforms.py:211: UserWarning: The use of the transforms.Scale transform is deprecated, please use transforms.Resize instead.\n",
            "  \"please use transforms.Resize instead.\")\n",
            "Using downloaded and verified file: ./svhn/train_32x32.mat\n",
            "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz to ./mnist/MNIST/raw/train-images-idx3-ubyte.gz\n",
            "9920512it [00:01, 9225101.08it/s]                 \n",
            "Extracting ./mnist/MNIST/raw/train-images-idx3-ubyte.gz to ./mnist/MNIST/raw\n",
            "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz to ./mnist/MNIST/raw/train-labels-idx1-ubyte.gz\n",
            "32768it [00:00, 129179.11it/s]\n",
            "Extracting ./mnist/MNIST/raw/train-labels-idx1-ubyte.gz to ./mnist/MNIST/raw\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz to ./mnist/MNIST/raw/t10k-images-idx3-ubyte.gz\n",
            "1654784it [00:00, 2332472.07it/s]               \n",
            "Extracting ./mnist/MNIST/raw/t10k-images-idx3-ubyte.gz to ./mnist/MNIST/raw\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz to ./mnist/MNIST/raw/t10k-labels-idx1-ubyte.gz\n",
            "8192it [00:00, 43061.53it/s]\n",
            "Extracting ./mnist/MNIST/raw/t10k-labels-idx1-ubyte.gz to ./mnist/MNIST/raw\n",
            "Processing...\n",
            "/pytorch/torch/csrc/utils/tensor_numpy.cpp:141: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program.\n",
            "Done!\n",
            "Traceback (most recent call last):\n",
            "  File \"main.py\", line 58, in <module>\n",
            "    main(config)\n",
            "  File \"main.py\", line 23, in main\n",
            "    solver.train()\n",
            "  File \"/content/mnist-svhn-transfer/solver.py\", line 95, in train\n",
            "    fixed_mnist = self.to_var(mnist_iter.next()[0])\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/torch/utils/data/dataloader.py\", line 345, in __next__\n",
            "    data = self._next_data()\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/torch/utils/data/dataloader.py\", line 856, in _next_data\n",
            "    return self._process_data(data)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/torch/utils/data/dataloader.py\", line 881, in _process_data\n",
            "    data.reraise()\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/torch/_utils.py\", line 395, in reraise\n",
            "    raise self.exc_type(msg)\n",
            "RuntimeError: Caught RuntimeError in DataLoader worker process 0.\n",
            "Original Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/torch/utils/data/_utils/worker.py\", line 178, in _worker_loop\n",
            "    data = fetcher.fetch(index)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/torch/utils/data/_utils/fetch.py\", line 44, in fetch\n",
            "    data = [self.dataset[idx] for idx in possibly_batched_index]\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/torch/utils/data/_utils/fetch.py\", line 44, in <listcomp>\n",
            "    data = [self.dataset[idx] for idx in possibly_batched_index]\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/torchvision/datasets/mnist.py\", line 97, in __getitem__\n",
            "    img = self.transform(img)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/torchvision/transforms/transforms.py\", line 61, in __call__\n",
            "    img = t(img)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/torchvision/transforms/transforms.py\", line 166, in __call__\n",
            "    return F.normalize(tensor, self.mean, self.std, self.inplace)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/torchvision/transforms/functional.py\", line 208, in normalize\n",
            "    tensor.sub_(mean).div_(std)\n",
            "RuntimeError: output with shape [1, 32, 32] doesn't match the broadcast shape [3, 32, 32]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nu_Ht2UxuZFZ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 388
        },
        "outputId": "50f6f8f2-e76c-405b-a999-5e6f0626b100"
      },
      "source": [
        "import argparse\n",
        "import os\n",
        "from solver import Solver\n",
        "from torch.backends import cudnn\n",
        "from data_loader import get_loader\n",
        "\n",
        "def str2bool(v):\n",
        "    return v.lower() in ('true')\n",
        "\n",
        "def main(config):\n",
        "    svhn_loader, mnist_loader = get_loader(config)\n",
        "    \n",
        "    solver = Solver(config, svhn_loader, mnist_loader)\n",
        "    cudnn.benchmark = True \n",
        "    \n",
        "    # create directories if not exist\n",
        "    if not os.path.exists(config.model_path):\n",
        "        os.makedirs(config.model_path)\n",
        "    if not os.path.exists(config.sample_path):\n",
        "        os.makedirs(config.sample_path)\n",
        "    \n",
        "    if config.mode == 'train':\n",
        "        solver.train()\n",
        "    elif config.mode == 'sample':\n",
        "        solver.sample()\n",
        "\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    parser = argparse.ArgumentParser()\n",
        "    \n",
        "    # model hyper-parameters\n",
        "    parser.add_argument('--image_size', type=int, default=32)\n",
        "    parser.add_argument('--g_conv_dim', type=int, default=64)\n",
        "    parser.add_argument('--d_conv_dim', type=int, default=64)\n",
        "    parser.add_argument('--use_reconst_loss', required=True, type=str2bool)\n",
        "    parser.add_argument('--use_labels', required=True, type=str2bool)\n",
        "    parser.add_argument('--num_classes', type=int, default=10)\n",
        "    \n",
        "    # training hyper-parameters\n",
        "    parser.add_argument('--train_iters', type=int, default=40000)\n",
        "    parser.add_argument('--batch_size', type=int, default=64)\n",
        "    parser.add_argument('--num_workers', type=int, default=2)\n",
        "    parser.add_argument('--lr', type=float, default=0.0002)\n",
        "    parser.add_argument('--beta1', type=float, default=0.5)\n",
        "    parser.add_argument('--beta2', type=float, default=0.999)\n",
        "    \n",
        "    # misc\n",
        "    parser.add_argument('--mode', type=str, default='train')\n",
        "    parser.add_argument('--model_path', type=str, default='./models')\n",
        "    parser.add_argument('--sample_path', type=str, default='./samples')\n",
        "    parser.add_argument('--mnist_path', type=str, default='./mnist')\n",
        "    parser.add_argument('--svhn_path', type=str, default='./svhn')\n",
        "    parser.add_argument('--log_step', type=int , default=10)\n",
        "    parser.add_argument('--sample_step', type=int , default=500)\n",
        "\n",
        "    config = parser.parse_args()\n",
        "    print(config)\n",
        "    main(config)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ModuleNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-5-ae31007cb375>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0margparse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0msolver\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mSolver\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackends\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mcudnn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mdata_loader\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mget_loader\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'solver'",
            "",
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
          ]
        }
      ]
    }
  ]
}