{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "hair_classification.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyPWgbuKo7gwzWZn9Fg6yEF6",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/dlguswn3659/2020_Image_Lab/blob/master/hair_classification_recent_ver.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3Me4zvhOxFsm",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "a4ff2cb0-a7e2-486f-dc49-cbd47fe5da8b"
      },
      "source": [
        "from google.colab import drive\n",
        "\n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9E3B51tOxpdj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!pip install -q tensorflow-io\n",
        "!pip install -q pydicom"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zKqZAwEHxsb-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from PIL import Image\n",
        "import cv2\n",
        "import os\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import pydicom\n",
        "from pydicom.data import get_testdata_files\n",
        "import numpy as np\n",
        "\n",
        "import tensorflow as tf\n",
        "import tensorflow_io as tfio"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EhtoGbJLxx9-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!pip install -q pydicom"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4tHcXJKMykrO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Set the random seed number for reproducible results\n",
        "seedNum = 1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Mg09uqnXJnsX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Set the TensorFlow version to 2.x in Colab\n",
        "%tensorflow_version 2.x"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5t0saa6fJqCD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import random\n",
        "random.seed(seedNum)\n",
        "import numpy as np\n",
        "np.random.seed(seedNum)\n",
        "import tensorflow as tf\n",
        "tf.random.set_seed(seedNum)\n",
        "from tensorflow.keras import Sequential\n",
        "from tensorflow.keras.layers import Dense\n",
        "from tensorflow.keras.layers import Flatten\n",
        "from tensorflow.keras.layers import Dropout\n",
        "from tensorflow.keras.layers import Conv2D\n",
        "from tensorflow.keras.layers import MaxPooling2D\n",
        "from tensorflow.keras.layers import BatchNormalization\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "import pandas as pd\n",
        "import math\n",
        "import os\n",
        "import sys\n",
        "import shutil\n",
        "import urllib.request\n",
        "import zipfile\n",
        "import smtplib\n",
        "from matplotlib import pyplot\n",
        "from matplotlib.image import imread\n",
        "from datetime import datetime\n",
        "from email.message import EmailMessage"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oZHrr-DyJsET",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "gpu_info = !nvidia-smi\n",
        "gpu_info = '\\n'.join(gpu_info)\n",
        "if gpu_info.find('failed') >= 0:\n",
        "  print('Select the Runtime → \"Change runtime type\" menu to enable a GPU accelerator, ')\n",
        "  print('and then re-execute this cell.')\n",
        "else:\n",
        "  print(gpu_info)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OKkb9iXSJuN5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# plot diagnostic learning curves\n",
        "def summarize_diagnostics(history):\n",
        "\tfig, axs = pyplot.subplots(2, 1, figsize=(12,12))\n",
        "\t# plot loss\n",
        "\tpyplot.subplot(211)\n",
        "\tpyplot.title('Cross Entropy Loss')\n",
        "\tpyplot.plot(history.history['loss'], color='blue', label='train')\n",
        "\tpyplot.plot(history.history['val_loss'], color='red', label='test')\n",
        "\t# plot accuracy\n",
        "\tpyplot.subplot(212)\n",
        "\tpyplot.title('Classification Accuracy')\n",
        "\tpyplot.plot(history.history['accuracy'], color='blue', label='train')\n",
        "\tpyplot.plot(history.history['val_accuracy'], color='red', label='test')\n",
        "\tpyplot.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eYInvzMSJwcQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "startTimeScript = datetime.now()\n",
        "\n",
        "# Set up the number of CPU cores available for multi-thread processing\n",
        "n_jobs = -1\n",
        "print(\"Num GPUs Available: \", len(tf.config.experimental.list_physical_devices('GPU')))\n",
        "\n",
        "# Set up the flag to stop sending progress emails (setting to True will send status emails!)\n",
        "notifyStatus = False\n",
        "\n",
        "# Set up the mountStorage flag to mount G Drive for storing files (setting True will mount the drive!)\n",
        "mountStorage = False"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Gwo8RcnbO0IX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Set the default optimizer for the remaining portion of the script\n",
        "default_opt = Adam(learning_rate=0.001)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oUjLw4i9O6-Z",
        "colab_type": "text"
      },
      "source": [
        "# **Section 1. Data Preparation**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MTnrjedEVClW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# define location of dataset\n",
        "folder = '/content/gdrive/My Drive/ISIC-melanoma/train/'\n",
        "folder2 = '/content/gdrive/My Drive/ISIC-melanoma/hair_labeling/'\n",
        "# plot first few images\n",
        "hair_label = []\n",
        "image_field = []\n",
        "\n",
        "# start_num = 15719\n",
        "# end_num = 100000\n",
        "\n",
        "# start_num = 100000\n",
        "# end_num = 405555\n",
        "\n",
        "start_num = 405652\n",
        "end_num = 695029\n",
        "\n",
        "# start_num = 695059\n",
        "# end_num = 999642\n",
        "\n",
        "# start_num = 1000328\n",
        "# end_num = 1307396\n",
        "\n",
        "# start_num = 1307419\n",
        "# end_num = 1601764\n",
        "\n",
        "# start_num = 1601784\n",
        "# end_num = 1894741\n",
        "\n",
        "# start_num = 1894782\n",
        "# end_num = 2188465\n",
        "\n",
        "# start_num = 2188566\n",
        "# end_num = 2491594\n",
        "\n",
        "file_name = str(start_num) + '_' + str(end_num) + '.csv'\n",
        "\n",
        "target_row = 1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OJaAV61IVFAU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "######hair이 있는 사진들에 대해서!###########\n",
        "import csv\n",
        "\n",
        "hair_image_file = []\n",
        "\n",
        "ct = 1\n",
        "\n",
        "with open(folder2 + file_name, newline='') as myfile:\n",
        "    reader  = csv.reader(myfile, delimiter=',')\n",
        "    for i in reader:\n",
        "        if i[1] == '1':\n",
        "          hair_image_file.append(i[0])\n",
        "        ct += 1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ybQNecoIXCPs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "##center crop size ratio\n",
        "width_ratio = 1\n",
        "height_ratio = 2/3\n",
        "\n",
        "\n",
        "for i in range (1, 10):#원랜 (1, ct + 1)\n",
        "  if os.path.isfile(folder + hair_image_file[i] + '.dcm'):\n",
        "    filename = folder + hair_image_file[i] + '.dcm'\n",
        "    dataset = pydicom.dcmread(filename)\n",
        "\n",
        "    image_bytes = tf.io.read_file(filename)\n",
        "\n",
        "    image = tfio.image.decode_dicom_image(image_bytes, dtype=tf.uint16)\n",
        "\n",
        "    skipped = tfio.image.decode_dicom_image(image_bytes, on_error='skip', dtype=tf.uint8)\n",
        "\n",
        "    image_info = np.squeeze(image.numpy())\n",
        "\n",
        "    rows = int(dataset.Rows) #높이\n",
        "    cols = int(dataset.Columns) #너비\n",
        "\n",
        "    left = (cols) # 여기 작성하다 맘\n",
        "\n",
        "    # print(\"original image\")\n",
        "    # plt.imshow(np.squeeze(image.numpy()))\n",
        "    # plt.set_title('original image')\n",
        "    # plt.show()\n",
        "\n",
        "\n",
        "    image = cv2.cvtColor(dataset.pixel_array, cv2.COLOR_BGR2GRAY)\n",
        "\n",
        "    plt.imshow(image, cmap='gray')\n",
        "    plt.show()\n",
        "\n",
        "    label = input('(0 : no hair | 1 : hair)');\n",
        "    hair_label.append(label)\n",
        "    image_field.append(hair_image_file[i])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UXRHMm65xzAF",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 905
        },
        "outputId": "3a187640-0bfa-491a-a3e2-7dc236a75d7c"
      },
      "source": [
        "# define location of dataset\n",
        "folder = '/content/gdrive/My Drive/ISIC-melanoma/train/'\n",
        "\n",
        "filename = folder + 'ISIC_0015719.dcm'\n",
        "\n",
        "dataset = pydicom.dcmread(filename)\n",
        "\n",
        "image_bytes = tf.io.read_file(filename)\n",
        "\n",
        "image = tfio.image.decode_dicom_image(image_bytes, dtype=tf.uint16)\n",
        "\n",
        "skipped = tfio.image.decode_dicom_image(image_bytes, on_error='skip', dtype=tf.uint8)\n",
        "\n",
        "image_info = np.squeeze(image.numpy())\n",
        "\n",
        "print(image_info)\n",
        "print(image_info.shape[0])\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[[143  87  54]\n",
            "  [143  87  54]\n",
            "  [145  86  54]\n",
            "  ...\n",
            "  [170 122 100]\n",
            "  [171 120  99]\n",
            "  [171 120  99]]\n",
            "\n",
            " [[146  87  53]\n",
            "  [146  87  53]\n",
            "  [146  87  55]\n",
            "  ...\n",
            "  [171 123 101]\n",
            "  [173 122 101]\n",
            "  [173 122 101]]\n",
            "\n",
            " [[147  88  54]\n",
            "  [147  88  54]\n",
            "  [149  89  55]\n",
            "  ...\n",
            "  [173 125 103]\n",
            "  [175 124 103]\n",
            "  [175 124 103]]\n",
            "\n",
            " ...\n",
            "\n",
            " [[117  69  47]\n",
            "  [117  69  47]\n",
            "  [116  68  46]\n",
            "  ...\n",
            "  [146 100  76]\n",
            "  [146 100  74]\n",
            "  [145  99  73]]\n",
            "\n",
            " [[116  68  46]\n",
            "  [116  68  46]\n",
            "  [116  68  46]\n",
            "  ...\n",
            "  [146 100  76]\n",
            "  [145  99  73]\n",
            "  [146 100  74]]\n",
            "\n",
            " [[115  67  45]\n",
            "  [115  67  45]\n",
            "  [115  67  45]\n",
            "  ...\n",
            "  [147 101  78]\n",
            "  [147 101  75]\n",
            "  [149 103  77]]]\n",
            "4000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "piSrCna8SvDv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# organize dataset into a useful structure\n",
        "from os import makedirs\n",
        "from os import listdir\n",
        "from shutil import copyfile\n",
        "from random import seed\n",
        "from random import random\n",
        "# create directories\n",
        "dataset_home = 'dataset_dogs_vs_cats/'\n",
        "subdirs = ['train/', 'test/']\n",
        "for subdir in subdirs:\n",
        "\t# create label subdirectories\n",
        "\tlabeldirs = ['dogs/', 'cats/']\n",
        "\tfor labldir in labeldirs:\n",
        "\t\tnewdir = dataset_home + subdir + labldir\n",
        "\t\tmakedirs(newdir, exist_ok=True)\n",
        "# seed random number generator\n",
        "seed(seedNum)\n",
        "# define ratio of pictures to use for validation\n",
        "val_ratio = 0.25\n",
        "# copy training dataset images into subdirectories\n",
        "src_directory = 'train/'\n",
        "for file in listdir(src_directory):\n",
        "\tsrc = src_directory + '/' + file\n",
        "\tdst_dir = 'train/'\n",
        "\tif random() < val_ratio:\n",
        "\t\tdst_dir = 'test/'\n",
        "\tif file.startswith('cat'):\n",
        "\t\tdst = dataset_home + dst_dir + 'cats/'  + file\n",
        "\t\tcopyfile(src, dst)\n",
        "\telif file.startswith('dog'):\n",
        "\t\tdst = dataset_home + dst_dir + 'dogs/'  + file\n",
        "\t\tcopyfile(src, dst)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lTLBFg1oSpdm",
        "colab_type": "text"
      },
      "source": [
        "# **Section 2. Fit and Evaluate Models**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T13x8rU1SoIs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# baseline model with One Block VGG Model\n",
        "startTimeModule = datetime.now()\n",
        "tf.random.set_seed(seedNum)\n",
        "\n",
        "# define cnn model\n",
        "def define_model1():\n",
        "\tmodel = Sequential()\n",
        "\tmodel.add(Conv2D(32, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same', input_shape=(200, 200, 3)))\n",
        "\tmodel.add(MaxPooling2D((2, 2)))\n",
        "\tmodel.add(Flatten())\n",
        "\tmodel.add(Dense(128, activation='relu', kernel_initializer='he_uniform'))\n",
        "\tmodel.add(Dense(1, activation='sigmoid'))\n",
        "\t# compile model\n",
        "\tmodel.compile(optimizer=default_opt, loss='binary_crossentropy', metrics=['accuracy'])\n",
        "\treturn model\n",
        "\n",
        "# run the test harness for evaluating a model\n",
        "def run_test_harness():\n",
        "\t# define model\n",
        "\tmodel1 = define_model1()\n",
        "\t# create data generator\n",
        "\tdatagen = ImageDataGenerator(rescale=1.0/255.0)\n",
        "\t# prepare iterators\n",
        "\ttrain_it = datagen.flow_from_directory('dataset_dogs_vs_cats/train/',\n",
        "\t\tclass_mode='binary', batch_size=64, target_size=(200, 200))\n",
        "\ttest_it = datagen.flow_from_directory('dataset_dogs_vs_cats/test/',\n",
        "\t\tclass_mode='binary', batch_size=64, target_size=(200, 200))\n",
        "\t# fit model\n",
        "\thistory = model1.fit(train_it, steps_per_epoch=len(train_it),\n",
        "\t\tvalidation_data=test_it, validation_steps=len(test_it), epochs=20, verbose=1)\n",
        "\t# evaluate model\n",
        "\t_, acc = model1.evaluate(test_it, steps=len(test_it), verbose=0)\n",
        "\tprint('> %.3f' % (acc * 100.0))\n",
        "\t# learning curves\n",
        "\tsummarize_diagnostics(history)\n",
        "\n",
        "# entry point, run the test harness\n",
        "run_test_harness()\n",
        "print('Total time for the model processing:', (datetime.now() - startTimeModule))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9YMcqNzAS_L0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# baseline model with Two Block VGG Model\n",
        "startTimeModule = datetime.now()\n",
        "tf.random.set_seed(seedNum)\n",
        "\n",
        "# define cnn model\n",
        "def define_model2():\n",
        "\tmodel = Sequential()\n",
        "\tmodel.add(Conv2D(32, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same', input_shape=(200, 200, 3)))\n",
        "\tmodel.add(MaxPooling2D((2, 2)))\n",
        "\tmodel.add(Conv2D(64, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same'))\n",
        "\tmodel.add(MaxPooling2D((2, 2)))\n",
        "\tmodel.add(Flatten())\n",
        "\tmodel.add(Dense(128, activation='relu', kernel_initializer='he_uniform'))\n",
        "\tmodel.add(Dense(1, activation='sigmoid'))\n",
        "\t# compile model\n",
        "\tmodel.compile(optimizer=default_opt, loss='binary_crossentropy', metrics=['accuracy'])\n",
        "\treturn model\n",
        "\n",
        "# run the test harness for evaluating a model\n",
        "def run_test_harness():\n",
        "\t# define model\n",
        "\tmodel2 = define_model2()\n",
        "\t# create data generator\n",
        "\tdatagen = ImageDataGenerator(rescale=1.0/255.0)\n",
        "\t# prepare iterators\n",
        "\ttrain_it = datagen.flow_from_directory('dataset_dogs_vs_cats/train/',\n",
        "\t\tclass_mode='binary', batch_size=64, target_size=(200, 200))\n",
        "\ttest_it = datagen.flow_from_directory('dataset_dogs_vs_cats/test/',\n",
        "\t\tclass_mode='binary', batch_size=64, target_size=(200, 200))\n",
        "\t# fit model\n",
        "\thistory = model2.fit(train_it, steps_per_epoch=len(train_it),\n",
        "\t\tvalidation_data=test_it, validation_steps=len(test_it), epochs=20, verbose=1)\n",
        "\t# evaluate model\n",
        "\t_, acc = model2.evaluate(test_it, steps=len(test_it), verbose=0)\n",
        "\tprint('> %.3f' % (acc * 100.0))\n",
        "\t# learning curves\n",
        "\tsummarize_diagnostics(history)\n",
        "\n",
        "# entry point, run the test harness\n",
        "run_test_harness()\n",
        "print('Total time for the model processing:', (datetime.now() - startTimeModule))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j0OORFWSTBwl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# baseline model with Three Block VGG Model\n",
        "startTimeModule = datetime.now()\n",
        "tf.random.set_seed(seedNum)\n",
        "\n",
        "# define cnn model\n",
        "def define_model3():\n",
        "\tmodel = Sequential()\n",
        "\tmodel.add(Conv2D(32, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same', input_shape=(200, 200, 3)))\n",
        "\tmodel.add(MaxPooling2D((2, 2)))\n",
        "\tmodel.add(Conv2D(64, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same'))\n",
        "\tmodel.add(MaxPooling2D((2, 2)))\n",
        "\tmodel.add(Conv2D(128, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same'))\n",
        "\tmodel.add(MaxPooling2D((2, 2)))\n",
        "\tmodel.add(Flatten())\n",
        "\tmodel.add(Dense(128, activation='relu', kernel_initializer='he_uniform'))\n",
        "\tmodel.add(Dense(1, activation='sigmoid'))\n",
        "\t# compile model\n",
        "\tmodel.compile(optimizer=default_opt, loss='binary_crossentropy', metrics=['accuracy'])\n",
        "\treturn model\n",
        "\n",
        "# run the test harness for evaluating a model\n",
        "def run_test_harness():\n",
        "\t# define model\n",
        "\tmodel3 = define_model3()\n",
        "\t# create data generator\n",
        "\tdatagen = ImageDataGenerator(rescale=1.0/255.0)\n",
        "\t# prepare iterators\n",
        "\ttrain_it = datagen.flow_from_directory('dataset_dogs_vs_cats/train/',\n",
        "\t\tclass_mode='binary', batch_size=64, target_size=(200, 200))\n",
        "\ttest_it = datagen.flow_from_directory('dataset_dogs_vs_cats/test/',\n",
        "\t\tclass_mode='binary', batch_size=64, target_size=(200, 200))\n",
        "\t# fit model\n",
        "\thistory = model3.fit(train_it, steps_per_epoch=len(train_it),\n",
        "\t\tvalidation_data=test_it, validation_steps=len(test_it), epochs=20, verbose=1)\n",
        "\t# evaluate model\n",
        "\t_, acc = model3.evaluate(test_it, steps=len(test_it), verbose=0)\n",
        "\tprint('> %.3f' % (acc * 100.0))\n",
        "\t# learning curves\n",
        "\tsummarize_diagnostics(history)\n",
        "\n",
        "# entry point, run the test harness\n",
        "run_test_harness()\n",
        "print('Total time for the model processing:', (datetime.now() - startTimeModule))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "67jD0r7STHlr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# baseline model with VGG-3 and dropout (variation #1)\n",
        "startTimeModule = datetime.now()\n",
        "tf.random.set_seed(seedNum)\n",
        "\n",
        "# define cnn model\n",
        "def define_model4():\n",
        "\tmodel = Sequential()\n",
        "\tmodel.add(Conv2D(32, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same', input_shape=(200, 200, 3)))\n",
        "\tmodel.add(MaxPooling2D((2, 2)))\n",
        "\tmodel.add(Dropout(0.2))\n",
        "\tmodel.add(Conv2D(64, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same'))\n",
        "\tmodel.add(MaxPooling2D((2, 2)))\n",
        "\tmodel.add(Dropout(0.2))\n",
        "\tmodel.add(Conv2D(128, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same'))\n",
        "\tmodel.add(MaxPooling2D((2, 2)))\n",
        "\tmodel.add(Dropout(0.2))\n",
        "\tmodel.add(Flatten())\n",
        "\tmodel.add(Dense(128, activation='relu', kernel_initializer='he_uniform'))\n",
        "\tmodel.add(Dropout(0.5))\n",
        "\tmodel.add(Dense(1, activation='sigmoid'))\n",
        "\t# compile model\n",
        "\tmodel.compile(optimizer=default_opt, loss='binary_crossentropy', metrics=['accuracy'])\n",
        "\treturn model\n",
        "\n",
        "# run the test harness for evaluating a model\n",
        "def run_test_harness():\n",
        "\t# define model\n",
        "\tmodel4 = define_model4()\n",
        "\t# create data generator\n",
        "\tdatagen = ImageDataGenerator(rescale=1.0/255.0)\n",
        "\t# prepare iterator\n",
        "\ttrain_it = datagen.flow_from_directory('dataset_dogs_vs_cats/train/',\n",
        "\t\tclass_mode='binary', batch_size=64, target_size=(200, 200))\n",
        "\ttest_it = datagen.flow_from_directory('dataset_dogs_vs_cats/test/',\n",
        "\t\tclass_mode='binary', batch_size=64, target_size=(200, 200))\n",
        "\t# fit model\n",
        "\thistory = model4.fit(train_it, steps_per_epoch=len(train_it),\n",
        "\t\tvalidation_data=test_it, validation_steps=len(test_it), epochs=50, verbose=1)\n",
        "\t# evaluate model\n",
        "\t_, acc = model4.evaluate(test_it, steps=len(test_it), verbose=0)\n",
        "\tprint('> %.3f' % (acc * 100.0))\n",
        "\t# learning curves\n",
        "\tsummarize_diagnostics(history)\n",
        "\n",
        "# entry point, run the test harness\n",
        "run_test_harness()\n",
        "print('Total time for the model processing:', (datetime.now() - startTimeModule))"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}